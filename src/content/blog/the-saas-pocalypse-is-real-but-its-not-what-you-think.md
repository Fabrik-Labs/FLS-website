---
title: "The SaaS-pocalypse Is Real. But It's Not What You Think."
date: 2026-02-25
description: "AI is making custom software faster and cheaper to build — but it's not magic. Here's what the SaaS-pocalypse means for nonprofits and ed-tech teams."
author: Brad Sukala
featuredImage: /images/blog/saaspocalypse-image.png
---
***How AI is changing the math on custom software — and why that's good news for mission-driven teams.***

If you follow tech news at all, you've probably heard some version of the story: AI is coming for software. Wall Street panicked in early February after Anthropic released a set of AI tools that could automate legal work, financial analysis, and a bunch of other stuff that used to require expensive specialized software. Software stocks dropped — hard. Nearly $300 billion in market value disappeared in a single day. People started calling it the *SaaS-pocalypse*.

Around the same time, Matt Shumer — a tech entrepreneur and AI startup CEO — published a viral essay called ["Something Big Is Happening"](https://x.com/mattshumer_/status/2021256989876109403) that racked up tens of millions of views. His argument: AI isn't just getting better at writing code. It's getting good enough to *do the work itself*. He described telling an AI what to build in plain English, walking away for four hours, and coming back to a finished product. His conclusion was essentially: the robots are here, start preparing.

If you're running a nonprofit or ed-tech organization and reading all of this, you'd be forgiven for feeling one of two things: either terrified, or skeptical that any of it applies to you.

I think both reactions are wrong — or at least incomplete. Here's how I see it.

## The hype is real, but so are the limits

Let's start with what's actually true. AI *is* making it dramatically faster and cheaper to build software. Tasks that used to take a team of developers weeks can now be prototyped in hours. The cost of getting from *idea* to *working thing* has dropped significantly. And this trend is accelerating — the tools are getting better every few months, not every few years.

That part isn't hype. I use these tools every day, and the improvement curve is steep.

But here's where the narrative falls apart: building a working prototype is not the same thing as building software that actually solves your problem. And this is where the "AI will replace everything" crowd loses me.

Gary Marcus, a well-known AI researcher, [called Shumer's essay "weaponized hype."](https://garymarcus.substack.com/p/about-that-matt-shumer-post-that) He pointed out that the benchmarks Shumer cited for AI coding accuracy use a 50% success threshold — meaning the AI gets it right half the time. That's impressive for a research benchmark. It's not impressive if you're deploying software that your team relies on every day. [Fortune's analysis](https://fortune.com/2026/02/12/matt-shumers-viral-blog-about-ais-looming-impact-on-knowledge-workers-is-based-on-flawed-assumptions/) made a similar point: the developers having the most success with fully autonomous AI coding tend to be solo operators working on greenfield projects with no legacy systems, no compliance requirements, and no organizational complexity. That's not most organizations. It's certainly not most nonprofits.

The [Retool 2026 Build vs. Buy report](https://www.businesswire.com/news/home/20260217548274/en/Retools-2026-Build-vs.-Buy-Report-Reveals-35-of-Enterprises-Have-Already-Replaced-SaaS-With-Custom-Software) had a more grounded take. Yes, 35% of enterprises have already replaced at least one SaaS tool with something custom-built. And 78% plan to build more custom tools this year. But they also found that only 19% of organizations have what they'd call "advanced" AI automation maturity. The gap between "we built a prototype" and "we deployed production software that our team actually uses" is still significant.

As Retool's CEO put it: a prototype that runs on sample data is impressive. A production tool that connects to your actual systems, respects permissions, and passes a security review is *useful*. Those are very different things.

## So what does this actually mean for you?

Here's the part that I think gets lost in the noise, and the part that matters most for organizations like the ones we work with.

**The cost of building custom software just dropped dramatically.** Not to zero. Not to *anyone can do it*. But enough that the math has genuinely changed.

Two years ago, if you were a nonprofit with a $10 million budget and you needed a custom tool to manage a complex internal workflow, you were probably looking at a six-figure project with a multi-month timeline. The economics pushed you toward buying an off-the-shelf SaaS tool that sort of fit — and then spending years fighting with it, building workarounds, and wishing it did things differently.

That trade-off is shifting. The same project that might have cost $150K and taken six months can now often be done faster and for less — not because AI writes the whole thing, but because AI dramatically accelerates the work that skilled people are already doing. Developers write code faster. Designs iterate more quickly. Testing cycles compress. The humans are still driving, but they've got a much better engine.

And here's what that means practically: **custom software is no longer just for organizations with Fortune 500 budgets.** The kind of purpose-built tools that used to be out of reach for a $10M nonprofit are increasingly within reach.

That's not a small thing. For years, mission-driven organizations have been stuck choosing between expensive SaaS tools that don't quite fit and duct-taped spreadsheet solutions that everyone hates. The middle ground — something built specifically for how *your* team works — was too expensive. That's changing.

## The catch: you still need a guide

So if AI is making everything faster and cheaper, why can't you just do it yourself? Or hire the cheapest developer you can find and let the AI do the heavy lifting?

You *could*. And for simple things — a basic internal dashboard, a straightforward form — maybe that works. But for anything with real complexity — multiple systems that need to talk to each other, data that needs to stay secure, workflows that involve real judgment calls — the AI isn't the hard part. The hard part is the same as it's always been:

**Figuring out what to build.**

One of the best observations I've seen in this whole debate came from a [Quillette essay responding to Shumer](https://quillette.com/2026/02/16/keep-calm-and-adapt-ai-matt-shumer-automation/): "The hard part is discovering what the system actually needs to do, not writing the functions that implement it." Software projects don't fail because the code was written too slowly. They fail because someone built the wrong thing, or built the right thing for the wrong workflow, or didn't think through how it would fit into the organization's actual operations.

AI accelerates the building. It doesn't replace the thinking. And if anything, faster building makes good thinking *more* important, not less — because you can now waste money faster, too.

This is where I'll be direct about our perspective at Fabrik Labs: we think this moment is genuinely exciting for the organizations we serve. Not because AI is magic — it's not — but because it's shifted the economics enough that teams who were priced out of custom software now have real options. And the organizations that will get the most out of this shift are the ones who pair the new tools with experienced product thinking.

Not just *someone who knows how to prompt an AI*. Someone who knows how to sit with your team, understand your actual workflows, push back on assumptions, and figure out what would actually make a difference — before anyone writes a line of code.

## The bottom line

The SaaS-pocalypse narrative isn't totally wrong. AI *is* disrupting the economics of software, and some of the generic, overpriced SaaS tools that mission-driven organizations have been stuck with are going to have a harder time justifying their price tags. That's a good thing for you.

But the *AI builds everything for free* narrative isn't right either. The technology has gotten remarkably good at the *execution* part of software development. What it hasn't gotten good at — and won't anytime soon — is the *judgment* part. Understanding your organization. Knowing what questions to ask. Recognizing when you're solving the wrong problem. Designing something that people will actually use.

The opportunity right now, for nonprofits and ed-tech teams especially, is to take advantage of the fact that the execution cost has dropped while the value of good judgment hasn't. That's a window. And organizations that move through it thoughtfully — with the right guidance — are going to end up with tools that fit their work in ways that off-the-shelf software never could.

That's not a future prediction. That's happening now.

---

*Brad is the owner and managing partner of [Fabrik Labs](https://www.fabriklabs.co/), a product consultancy that helps nonprofits and ed-tech organizations build custom software. If you're thinking about whether custom development might be the right move for your team, [let's talk](https://cal.com/fabrikbrad/1h-discovery).*
